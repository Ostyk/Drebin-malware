{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>\n",
       "code_show=true; \n",
       "function code_toggle() {\n",
       " if (code_show){\n",
       " $('div.input').hide();\n",
       " } else {\n",
       " $('div.input').show();\n",
       " }\n",
       " code_show = !code_show\n",
       "} \n",
       "$( document ).ready(code_toggle);\n",
       "</script>\n",
       "The raw code for this IPython notebook is by default hidden for easier reading.\n",
       "To toggle on/off the raw code, click <a href=\"javascript:code_toggle()\">here</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "HTML('''<script>\n",
    "code_show=true; \n",
    "function code_toggle() {\n",
    " if (code_show){\n",
    " $('div.input').hide();\n",
    " } else {\n",
    " $('div.input').show();\n",
    " }\n",
    " code_show = !code_show\n",
    "} \n",
    "$( document ).ready(code_toggle);\n",
    "</script>\n",
    "The raw code for this IPython notebook is by default hidden for easier reading.\n",
    "To toggle on/off the raw code, click <a href=\"javascript:code_toggle()\">here</a>.''')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Homework 1\n",
    "* Michal Ostyk-Narbutt 2018/2019\n",
    "* Matricola: 1854051\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from matplotlib import rc\n",
    "import scipy.stats as st\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from uncertainties import unumpy\n",
    "import itertools\n",
    "rc('font', **{'family': 'serif', 'serif': ['Computer Modern']})\n",
    "rc('text', usetex=True)\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold,KFold\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score\n",
    "from sklearn.metrics import classification_report, recall_score, f1_score\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#own files\n",
    "import reading as read\n",
    "import ML_models as ml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Malware detection\n",
    "• With all the applications in the dataset create a binary\n",
    "classifier whose output is\n",
    "– malware\n",
    "– non malware.\n",
    "• Use the dictionary file as ground truth.\n",
    "• Evaluate the performance of the classifier.\n",
    "\n",
    "\n",
    "Bayesian approach (e.g. SPAM filter), no need to match\n",
    "features with numerical value\n",
    "* Other classification algorithm (SVM, Random Forest…), in this\n",
    "case you need a match beetwen the string features and\n",
    "numerical value.\n",
    "* Try to use not all set of features but only a few (permissions,\n",
    "api calls, urls).\n",
    "* Use the paper as reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "There are 5560 positive instance(s) and 5560 negative instance(s)\n",
      "Loading positive data ...\n",
      "Loading negative data ...\n"
     ]
    }
   ],
   "source": [
    "positive, negative = read.data_balance(negative='BALANCED', \n",
    "                                  ML_type = 'Detection',\n",
    "                                  N_family_count = 'ALL',\n",
    "                                  printing=True)\n",
    "\n",
    "pos = read.data_extractor(positive,'positive',mypath='drebin',load_data=True)\n",
    "neg = read.data_extractor(negative,'negative',mypath='drebin',load_data=True)\n",
    "\n",
    "#divide data\n",
    "X = np.concatenate((pos, neg), axis=0)\n",
    "y = np.hstack((np.ones(len(pos)),np.zeros(len(neg))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split into test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "                        X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalize data by dividing by std\n",
    "X_train, X_test = ml.scale_set(X_train, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Bayesian approach\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>f1-score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <td>0.891758</td>\n",
       "      <td>0.845411</td>\n",
       "      <td>0.622038</td>\n",
       "      <td>0.716724</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       accuracy    recall  precision  f1-score\n",
       "model  0.891758  0.845411   0.622038  0.716724"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml.my_SVM(X_train, X_test,y_train, y_test, 10, 0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Malware Classification\n",
    "Create a classifier that given in input the features of a\n",
    "malware output the family it belongs to.\n",
    "* Use the dictionary as ground truth.\n",
    "* Evaluate the performance of the classifier.\n",
    "\n",
    "Select only malicious applications using the dictionary.\n",
    "* Select only malware families that have more than 20 samples.\n",
    "* Use a bayesian approach.\n",
    "* Use different classification algorithm (SVM, Random Forest…)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 5560 positive instance(s) and 5560 negative instance(s)\n",
      "Loading positive data ...\n"
     ]
    }
   ],
   "source": [
    "positive, negative = read.data_balance(negative='BALANCED', \n",
    "                                  ML_type = 'Classification',\n",
    "                                  N_family_count = 'ALL',\n",
    "                                  printing=True)\n",
    "\n",
    "pos = read.data_extractor(positive,'positive',mypath='drebin',load_data=True)\n",
    "#divide data\n",
    "X = np.concatenate((pos, neg), axis=0)\n",
    "y = np.hstack((np.ones(len(pos)),np.zeros(len(neg))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "                        pos, df['family'], test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Bayesian approach\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(X, y, n_splits=5, seed=10):\n",
    "    '''\n",
    "    Args: X-data, y-labels,\n",
    "    balanced - if True, makes dataset balanced\n",
    "    n_splits - K-fold cross validation splits\n",
    "\n",
    "    '''\n",
    "    C = [1, 10, 100, 1000]\n",
    "    gamma = [1e-3, 1e-2, 1/8]\n",
    "    permutations = [(x,y) for x in C for y in gamma]\n",
    "\n",
    "    kf = StratifiedKFold(n_splits=n_splits,random_state=42, shuffle=True)\n",
    "    np.random.seed(seed)\n",
    "    baseline = pd.DataFrame(np.zeros(4)).T\n",
    "    baseline.columns = ['accuracy','recall','precision','f1-score']\n",
    "\n",
    "    for p1,p2 in permutations:\n",
    "        print(\"$\\gamma$: {}, C = {}\".format(p2,p1))\n",
    "        empty = pd.DataFrame([],columns=['accuracy','recall','precision','f1-score'])\n",
    "\n",
    "        tprs = []\n",
    "        aucs = []\n",
    "        mean_fpr = np.linspace(0, 1, 100)\n",
    "        for train_index, test_index in kf.split(X,y):\n",
    "\n",
    "            X_train, X_test = X[train_index], X[test_index]\n",
    "            y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "            X_train, X_test = scale_set(X_train,X_test)\n",
    "\n",
    "            #metrics calcs\n",
    "            performance, roc = my_SVM(X_train, X_test, y_train, y_test,p1,p2)\n",
    "            empty = pd.concat([empty,performance])\n",
    "            print(performance)\n",
    "            #roc curve calcs\n",
    "            tprs.append(scipy.interp(mean_fpr, roc[0], roc[1]))\n",
    "            tprs[-1][0] = 0.0\n",
    "            roc_auc = auc(roc[0], roc[1])\n",
    "            aucs.append(roc_auc)\n",
    "\n",
    "        permuation_performance = empty.mean() #mean of scores for all CVs\n",
    "        \n",
    "        if np.array([permuation_performance['f1-score']])>=np.array([baseline['f1-score']]): #maximizing f1 score\n",
    "            baseline = pd.DataFrame(unumpy.uarray(permuation_performance, empty.std())).T\n",
    "\n",
    "            baseline.columns = ['accuracy','recall','precision','f1-score']\n",
    "            baseline['$C$'],baseline['$\\gamma$'] = p1, p2\n",
    "            tprs_best = tprs\n",
    "            aucs_best = aucs\n",
    "            mean_fpr_best = mean_fpr\n",
    "\n",
    "    r = {\"tprs\":tprs_best,\n",
    "         \"aucs\":aucs_best,\n",
    "         \"mean_fpr\":mean_fpr_best} #roc\n",
    "\n",
    "    #returning part\n",
    "    baseline.insert(0, 'Model', model_name)\n",
    "    \n",
    "    return baseline,r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#baseline,r = model(X, y, n_splits=4, seed=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roc(rocs,balanced=True):\n",
    "    '''plots the roc curve for a given model'''\n",
    "    plt.figure(figsize=(10,7))\n",
    "    plt.plot([0, 1], [0, 1], linestyle='--', lw=2, color='cyan',\n",
    "         label='Luck', alpha=.8)\n",
    "    colors = ['b','k','r']\n",
    "    for index, values in enumerate(rocs):\n",
    "        tprs = values['tprs']\n",
    "        aucs = values['aucs']\n",
    "        mean_fpr = values['mean_fpr']\n",
    "\n",
    "        mean_tpr = np.mean(tprs, axis=0)\n",
    "        mean_tpr[-1] = 1.0\n",
    "        mean_auc = auc(mean_fpr, mean_tpr)\n",
    "        std_auc = np.std(aucs)\n",
    "        plt.plot(mean_fpr, mean_tpr,\n",
    "                 label='AUC = {:.4f} $\\pm$ {:.4f}'.format(mean_auc, std_auc),\n",
    "                 lw=2, alpha=.8,color=colors[index])\n",
    "\n",
    "        std_tpr = np.std(tprs, axis=0)\n",
    "        tprs_upper = np.minimum(mean_tpr + std_tpr, 1)\n",
    "        tprs_lower = np.maximum(mean_tpr - std_tpr, 0)\n",
    "        plt.fill_between(mean_fpr, tprs_lower, tprs_upper, alpha=.2,color=colors[index])\n",
    "\n",
    "\n",
    "    plt.xlim([-0.05, 1.05])\n",
    "    plt.ylim([-0.05, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    #plt.title('Receiver operating characteristic of the {} model'.format(mode_name))\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
